<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>计算机基础 on 小贺的博客</title>
    <link>https://he2121.github.io/xiaohe-blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/</link>
    <description>Recent content in 计算机基础 on 小贺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 10 Apr 2022 11:10:12 +0800</lastBuildDate><atom:link href="https://he2121.github.io/xiaohe-blog/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Golang 内存分配器介绍</title>
      <link>https://he2121.github.io/xiaohe-blog/posts/golang/golang-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Sun, 10 Apr 2022 11:10:12 +0800</pubDate>
      
      <guid>https://he2121.github.io/xiaohe-blog/posts/golang/golang-%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8%E4%BB%8B%E7%BB%8D/</guid>
      <description>内存管理属于计算机中的基石，在各种操作系统以及编程语言的设计中，最重要考量之一在于内存管理部分。而内存管理中可以分成两个主要部分：内存分配与内存回收。今天我们主要来分析下 Golang 内存分配器的设计，也不可避免对内存回收有所提及
基础概念 🔗此节简单介绍下与此文相关的一些概念
内存布局 🔗用户程序所看到内存是操作系统为其分配的虚拟内存，其内存布局可分为以下五个部分：
 栈区（Stack）：存储程序执行期间的本地变量和函数的参数，从高地址向低地址生长 堆区（Heap）：动态内存分配区域，通过 malloc、new、free 和 delete 等函数管理 未初始化变量区（BSS）：存储未被初始化的全局变量和静态变量 数据区（Data）：存储在源代码中有预定义值的全局变量和静态变量 代码区（Text）：存储只读的程序执行代码，即机器指令  其中 BSS，Data，Text 区内存占用不会变化（分配和回收），也可称为静态内存。栈区内存会由编译器自动分配释放，而堆区上的内存需要应用手动申请与释放。所以虽然上述内存布局中存在有 5 个部分，但当我们谈及内存管理时，都是指的堆内存
堆内存管理方式 🔗手动管理 🔗C/C++ 系列的 malloc/free 的手动管理
优点：性能比较好
缺点
  对程序员心智压力大，容易出 bug
  内存泄漏：垃圾对象占用堆内存没有被释放
  悬挂指针：指向被释放的内存区域
    自动管理 🔗JAVA、Golang、 Python 等语言。主要存在两种自动回收方式：垃圾回收、引用计数
优点
 对程序员友好  缺点：性能有所损耗
内存分配 🔗内存分配主要有两种方式：线性分配器与空闲链表分配器，其它任何不同的内存分配器都是这两者方式的变种。
线性分配器 🔗线性分配器易产生内存碎片，所以使用这种分配器时要搭配合适的内存回收算法使用，如 java 中的标记-压缩，复制回收等算法
空闲链表分配器 🔗把内存分为一个个块，然后利用链表连接不同的内存块
这种方式可以重新利用回收的内存块，但是分配内存时需要遍历链表，时间复杂度 O(n)。
一般有以下几种方式在不同大小的内存块选择分配
 首次适应：从表头遍历，第一个大于申请内存的内存块 循环首次适应：从上次遍历结束位置开始遍历，第一个大于申请内存的内存块 最优适应：选择大小最合适的内存块 最差适用：选择最大内存块  Golang 内存分配器 🔗整体框架 🔗Golang 内存分配算法源自 Google 的 TCMalloc 算法（Thread-Caching），具有减少内存碎片，适用于多核，更好的并行性支持等特性，主要利用了多级缓存与大小分类的思想来优化内存分配速度。TCMalloc 整体框架如下。</description>
    </item>
    
    <item>
      <title>字符编码发展梳理</title>
      <link>https://he2121.github.io/xiaohe-blog/posts/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E5%8F%91%E5%B1%95%E6%A2%B3%E7%90%86/</link>
      <pubDate>Wed, 02 Mar 2022 00:38:28 +0800</pubDate>
      
      <guid>https://he2121.github.io/xiaohe-blog/posts/%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E5%8F%91%E5%B1%95%E6%A2%B3%E7%90%86/</guid>
      <description>从 Golang 中的字符串出发
  len(&amp;quot;ab你好&amp;quot;) 返回多少
  已经存在用下标遍历字符串的方式，为什么还要有for _,ch range str ，有什么区别
  从 ASCII 字符编码到 UTF-8 🔗起点: ASCII 码 🔗首先我们知道在计算机的世界中，一切数据都是以字节流的形式存在。例如下图，一个字节（8 个 bit）可以表示从 0 - 255 之间的整数。
但是我如果想表示一个字符呢？
字符定义：
 在电脑和电信领域中，字符（Character）是一个信息单位。对使用字母系统或音节文字等自然语言，它大约对应为一个音位、类音位的单位或符号。简单来讲就是一个汉字、假名、韩文字……，或是一个英文、其他西方语言的字母。字符的例子有：字母、数字系统或标点符号。
 此时需要一个字符与整数之间的映射关系。例如，用整数 97 -&amp;gt; a。你传入一个整数，并且指明这个整数是字符类型，那么计算机就给你显示成字符
这时候最通用的 ASCII (American Standard Code for Information Interchange，美国信息交换标准代码) 在 1963 年由美国国家标准协会提出。
最初版 ASCII 编码使用一个字节中的 7 个 bit 位 （整数 0-127）定义了整数到 128 个字符的映射关系。 ASCII 定义的 128 个字符与其编码方式如下图所示。
编码范围 🔗十进制: 0-127
字节形式：
ASCII 意义 🔗包含了使用最广泛的控制字符、数字符号、英文字母、英文符号，作为鼻祖，成为计算机编码系统的基础，以后出现的各种字符编码基本都要兼容它</description>
    </item>
    
    <item>
      <title>数据编码与演化</title>
      <link>https://he2121.github.io/xiaohe-blog/reading/ddia/%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E6%BC%94%E5%8C%96/</link>
      <pubDate>Sun, 16 Jan 2022 14:30:00 +0800</pubDate>
      
      <guid>https://he2121.github.io/xiaohe-blog/reading/ddia/%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E6%BC%94%E5%8C%96/</guid>
      <description>本文主要内容来自于《数据密集型应用系统设计》 第四章，推荐大家看原作
 背景 🔗在程序中，数据有两种不同的表示形式
  在内存中的数据结构： 对象，结构体，列表，数组，散列表，树等。
  如果要把内存中的数据结构保存到文件，或通过网络发送，则需要转换成字节序列（如 JSON ）
  两种不同表示的数据之间经常需要进行转换，从内存中数据结构转成字节序列成为 编码（encode）、序列化（serialization） 或 编组（marshalling）。反过来被称为 解码（Decoding） 、 **反序列化（deserialization）**或者 反编组( unmarshalling）
数据编码与演化 🔗1. 语言特定的格式 🔗首先比较常见的是各个编程语言内置对序列化的实现。例如 Python 中的 pickle、 Java 中的 java.io.Serializable 、Golang 中的 gob&amp;hellip;
但除非临时尝试中，我们一般不会使用它们。这是由于：
 这类编码通常与特定的编程语言深度绑定，其他语言很难读取这种数据，很难将系统与其他组织的系统（可能用的是不同的语言）进行集成 为了恢复相同对象类型的数据，解码过程需要实例化任意类的能力，这通常是安全问题的一个来源 在这些库中，数据版本控制通常是事后才考虑的。因为它们旨在快速简便地对数据进行编码，所以往往忽略了前向后向兼容性带来的麻烦问题 效率（编码或解码所花费的CPU时间，以及编码结构的大小）往往也是事后才考虑的。 例如，Java的内置序列化由于其糟糕的性能和臃肿的编码而臭名昭着  2. JSON、XML 文本格式编码 🔗现在比较常用的 JSON、XML 两种文本格式编码，其最大优点的是可以被多种编程语言读写， CSV 是另一种流行的与语言无关的格式，但其其功能相对较弱。下面是内存中的一个对象被编码成 JSON 格式后的示例，使用文本格式编码，不仅可以被多种编程语言解码（decoding），甚至连我们人类都能直接阅读理解其意思。
{  &amp;#34;userName&amp;#34;: &amp;#34;Martin&amp;#34;,  &amp;#34;favoriteNumber&amp;#34;: 1337,  &amp;#34;interests&amp;#34;: [&amp;#34;daydreaming&amp;#34;, &amp;#34;hacking&amp;#34;] } JSON、XML 得到了广泛的应用，但也有不少问题。例如 XML 格式的复杂与冗长。JSON 的流行则主要源于（通过成为JavaScript的一个子集）Web浏览器的内置支持，以及相对于XML的简单性。下面列数了它们的一些问题</description>
    </item>
    
    <item>
      <title>日志结构流派存储引擎的演化</title>
      <link>https://he2121.github.io/xiaohe-blog/reading/ddia/%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%B5%81%E6%B4%BE%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E6%BC%94%E5%8C%96/</link>
      <pubDate>Fri, 07 Jan 2022 14:30:00 +0800</pubDate>
      
      <guid>https://he2121.github.io/xiaohe-blog/reading/ddia/%E6%97%A5%E5%BF%97%E7%BB%93%E6%9E%84%E6%B5%81%E6%B4%BE%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E6%BC%94%E5%8C%96/</guid>
      <description>本文主要内容来自于《数据密集型应用系统设计》 第三章，内容对我很有启发，所以分享给大家，推荐看原作。
 背景 🔗存储引擎存在着两个主要流派：
 日志结构流派，只允许追加式更新/删除文件，不会修改已写入的文件，Bitcast，SSTables，LSM-Tree，LevelDB，RocksDB，Cassandra，HBase，Lucene 等属于此类 原地更新流派，将磁盘视为可以覆盖的一组固定大小的页。B-tree 就是这一流派的典型代表，已用于所有主流关系型数据库，以及大量的非关系数据库  大部分人已经对原地更新流派中 B-tree 已经比较熟悉了，但对日志结构流派并不是很了解，本文带领大家了解下其演化过程及 LSM-tree 与 B-tree 的对比
演化过程 🔗1. 一个最简单的数据库 🔗基本原理 🔗由两个 Bash 函数实现：
db_set(){  echo &amp;#34;$1,$2&amp;#34; &amp;gt;&amp;gt; database }  db_get(){  grep &amp;#34;^$1,&amp;#34; database | sed -e &amp;#34;s/^$1,//&amp;#34; | tail -n 1 } 插入/更新数据: 往 database 文本中追加一行 &amp;lt;key，value&amp;gt;
查询数据： 查找文本中最后一次出现的 &amp;lt;key，value&amp;gt;
例如：
➜ ~ db_set key1 val1 ➜ ~ db_set key2 val2 ➜ ~ db_set key1 val3 ➜ ~ cat database key1,val1 key2,val2 key1,val3 ➜ ~ db_get key1 val3 局限性 🔗db_set: 追加式写，性能高。但db_get: 从头扫描到尾，性能很差</description>
    </item>
    
    <item>
      <title>MESI 协议引发的一些思考</title>
      <link>https://he2121.github.io/xiaohe-blog/posts/mesi%E5%8D%8F%E8%AE%AE%E5%BC%95%E5%8F%91%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</link>
      <pubDate>Wed, 17 Nov 2021 14:30:00 +0800</pubDate>
      
      <guid>https://he2121.github.io/xiaohe-blog/posts/mesi%E5%8D%8F%E8%AE%AE%E5%BC%95%E5%8F%91%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</guid>
      <description>某个下午偶尔间看到了 MESI 缓存一致性协议，引出了我不少相关的疑惑，写下此文记录
 通过这篇文章你能了解到的知识 🔗 MESI 协议是什么，解决了什么问题 指令重排 是什么，解决了什么问题 内存屏障 是什么，解决了什么 MESI 与 并发同步的区别  MESI 缓存一致性协议 🔗MESI 产生的前提 🔗 多级缓存的出现 多核 CPU 的出现  总之为了计算机的性能，现代计算机都具备上述两点的设计，下图为不同存储的 IO 速度对比
MESI 解决的问题 🔗由于现在计算机都是多核 CPU 了，并且每一个 CPU 都有自己独立的缓存（如下图架构），这样就会有可能多个 cpu 操作同一份数据，导致各个 cpu 缓存中的同一份数据值不一致的情况。
MESI 的具体设计 🔗MESI：由缓存行（缓存中操作的基本单位，类似于磁盘的页）的四个状态首字母组成:
 Modified（修改）：这一行数据修改过了，与内存中的数据不一致了，这意味着如果其它 cpu 中的缓存具有这行数据，其状态要修改成 invalid Exclusive（独占）：只有一个 cache 读了这个数据行，并且没有修改过 Shared（共享）：有多个 cpu 的cahe 读了这个数据行，没有被修改过 Invalid（无效）：该缓存这一行的数据无效  状态流转 🔗缓存行的状态流转如下图，通过对各个缓存行状态位的控制，达到了多核 cpu 缓存中数据一致的目的
一个例子
 现在有两个 cpu，假定其缓存都为空，内存中有一个 x = 0 的数据 cpu1 通过 bus 从内存中读取 x， 该缓存行状态设置为 E cpu2 通过 bus 从内存中读取 x，cpu 1 嗅探到地址冲突，两个 cpu 中 x 所在缓存行状态位设置为 S cpu1 需要修改其缓存中 x 的值，设置其 x 所在缓存行状态为 M，通知 cpu2 把 x 所在缓存行状态位设置为 I，再修改缓存中 x 的值  **模拟网站：**https://www.</description>
    </item>
    
  </channel>
</rss>
